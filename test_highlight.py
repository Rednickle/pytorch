import torch.nn as nn

self.layer0 = nn.quantizable.fused.BachNormConv(activation='relu')
